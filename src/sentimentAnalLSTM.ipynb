{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'clean_reviews' (list)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd   \n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def clean_review(raw_review):\n",
    "\texample1 = BeautifulSoup(raw_review, 'html.parser').get_text()\n",
    "\t# print type(example1)\n",
    "\t# Use regular expressions to do a find-and-replace\n",
    "\tletters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "\t                      \" \",                   # The pattern to replace it with\n",
    "\t                      example1 )  # The text to search\n",
    "\t# print letters_only\n",
    "\tlower_case = letters_only.lower()        # Convert to lower case\n",
    "\twords = lower_case.split()               # Split into words\n",
    "\t# print words\n",
    "\t# print stopwords.words(\"english\")\n",
    "\twords = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "\t# print words\n",
    "\tfrom nltk.stem.porter import PorterStemmer\n",
    "\tporter_stemmer = PorterStemmer()\n",
    "\tstemmed_words = []\n",
    "\tfor i in range(len(words)):\n",
    "\t\tstemmed_words.append(porter_stemmer.stem(words[i]))\n",
    "\treturn( \" \".join( stemmed_words ))\n",
    "\n",
    "\n",
    "train = pd.read_csv(\"data\\IMDB\\labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n",
    "print(train.shape)\n",
    "# print train.columns.values\n",
    "num_reviews = train[\"review\"].size\n",
    "clean_reviews = []\n",
    "for i in range(10):\n",
    "\tif( (i+1)%1000 == 0 ):\n",
    "\t\tprint(\"Review %d of %d\\n\" % ( i+1, num_reviews )   )                                                       \n",
    "\tclean_reviews.append(clean_review(train[\"review\"][i]))\n",
    "%store clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n['classic', 'war', 'world', 'timothi', 'hine', 'entertain', 'film', 'obvious', 'goe', 'great', 'effort', 'length', 'faith', 'recreat', 'h', 'g', 'well', 'classic', 'book', 'mr', 'hine', 'succe', 'watch', 'film', 'appreci', 'fact', 'standard', 'predict', 'hollywood', 'fare', 'come', 'everi', 'year', 'e', 'g', 'spielberg', 'version', 'tom', 'cruis', 'slightest', 'resembl', 'book', 'obvious', 'everyon', 'look', 'differ', 'thing', 'movi', 'envis', 'amateur', 'critic', 'look', 'critic', 'everyth', 'other', 'rate', 'movi', 'import', 'base', 'like', 'entertain', 'peopl', 'never', 'agre', 'critic', 'enjoy', 'effort', 'mr', 'hine', 'put', 'faith', 'h', 'g', 'well', 'classic', 'novel', 'found', 'entertain', 'made', 'easi', 'overlook', 'critic', 'perceiv', 'shortcom']\n"
     ]
    }
   ],
   "source": [
    "print(len(clean_reviews))\n",
    "\n",
    "\n",
    "for i in range(len(clean_reviews)):\n",
    "    clean_reviews[i] = clean_reviews[i].split(' ')\n",
    "\n",
    "\n",
    "print(clean_reviews[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10    0\n11    1\n12    1\n13    0\n14    0\nName: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "clean_test_reviews = [] \n",
    "\n",
    "\n",
    "for i in range(10,15):\n",
    "    \n",
    "    clean_test_reviews.append( clean_review( train[\"review\"][i] ))\n",
    "    \n",
    "test_op = train[\"sentiment\"][10:15]\n",
    "print(test_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.tensorflowglove import tf_glove\n",
    "glovemodel = tf_glove.GloVeModel(embedding_size=300, context_size=10)\n",
    "glovemodel.fit_to_corpus(clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "glovemodel.train(num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-468f7bd9d583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_test_reviews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(type(test_op))\n",
    "print(clean_test_reviews[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "glovemodel.generate_tsne(\"sample_tsne.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10530826,  0.02363008,  1.59077251, ..., -0.63448429,\n        -0.86648047,  0.47548783],\n       [-1.17545474,  0.04726669, -0.57567799, ..., -0.6307568 ,\n         1.32035685, -1.55405879],\n       [ 1.24755621,  0.45703289, -1.70392239, ..., -0.41174126,\n        -0.57128203,  0.63591558],\n       ..., \n       [ 0.0372749 ,  0.14129621, -1.49726582, ...,  0.87931609,\n        -0.34475458, -1.074898  ],\n       [-1.88765693, -1.15654194,  0.58350301, ...,  0.39413834,\n        -0.2064212 ,  0.12882107],\n       [-0.35581797, -0.21454969,  1.72506869, ..., -0.27080706,\n         0.14710802,  0.62318963]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glovemodel.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#glovemodel.embeddings[glovemodel.id_for_word('kilo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(glovemodel.max_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 150  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'call'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-447fda5c933e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Pad sequences (samples x time)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_reviews\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_test_reviews\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x_train shape:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x_test shape:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Hariharan\\Anaconda3\\envs\\Deep\\lib\\site-packages\\keras\\preprocessing\\sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[1;31m# check `trunc` has expected shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
      "\u001b[0;32mC:\\Users\\Hariharan\\Anaconda3\\envs\\Deep\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'call'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(clean_reviews, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(clean_test_reviews, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(glovemodel.max_vocab_size, 300))\n",
    "model.add(LSTM(300, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-bc44fa392999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(x_train, np.array(train[\"sentiment\"][0:10]),\n\u001b[0m\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           validation_data=(x_test,np.array(test_op)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(x_train, np.array(train[\"sentiment\"][0:10]),\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test,np.array(test_op)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-37d575c2161e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m score, acc = model.evaluate(x_test, y_test,\n\u001b[0m\u001b[1;32m      2\u001b[0m                             batch_size=batch_size)\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Test accuracy:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n['classic', 'war', 'world', 'timothi', 'hine', 'entertain', 'film', 'obvious', 'goe', 'great', 'effort', 'length', 'faith', 'recreat', 'h', 'g', 'well', 'classic', 'book', 'mr', 'hine', 'succe', 'watch', 'film', 'appreci', 'fact', 'standard', 'predict', 'hollywood', 'fare', 'come', 'everi', 'year', 'e', 'g', 'spielberg', 'version', 'tom', 'cruis', 'slightest', 'resembl', 'book', 'obvious', 'everyon', 'look', 'differ', 'thing', 'movi', 'envis', 'amateur', 'critic', 'look', 'critic', 'everyth', 'other', 'rate', 'movi', 'import', 'base', 'like', 'entertain', 'peopl', 'never', 'agre', 'critic', 'enjoy', 'effort', 'mr', 'hine', 'put', 'faith', 'h', 'g', 'well', 'classic', 'novel', 'found', 'entertain', 'made', 'easi', 'overlook', 'critic', 'perceiv', 'shortcom']\n"
     ]
    }
   ],
   "source": [
    "print(np.array(train[\"sentiment\"][0:10])[0])\n",
    "print((clean_reviews[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}